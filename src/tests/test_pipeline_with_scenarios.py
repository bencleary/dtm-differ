"""
Automated tests for pipeline using generated test DTM scenarios.

These tests use the test DTMs generated by generate_test_dtms.py to validate
that the pipeline correctly handles various edge cases including nodata handling,
movement thresholds, and data quality validation.
"""

from __future__ import annotations

import tempfile
from pathlib import Path

import numpy as np
import pytest
import xdem

from dtm_differ.pipeline import run_pipeline
from dtm_differ.pipeline.types import ProcessingConfig


def test_scenario1_basic_movement(temp_output_dir, test_dtm_dir, db, test_job_id):
    """Test Scenario 1: Basic movement patterns with no nodata."""
    a_path = test_dtm_dir / "scenario1_dem_a.tif"
    b_path = test_dtm_dir / "scenario1_dem_b.tif"

    config = ProcessingConfig(
        t_green=1.0,
        t_amber=3.0,
        t_red=6.0,
        generate_report=False,
        generate_polygons=False,
    )

    db.create_job(test_job_id)
    result = run_pipeline(db, test_job_id, a_path, b_path, temp_output_dir, config)

    # Verify outputs exist
    assert result.map_layers_dir.exists()
    assert (result.map_layers_dir / "diff.tif").exists()
    assert (result.map_layers_dir / "elevation_change.tif").exists()
    assert (result.map_layers_dir / "movement_rank.tif").exists()

    # Verify movement ranking
    # Top-left: -2.0m (should be green: 1.0 <= 2.0 < 3.0)
    # Top-right: +3.0m (should be amber: 3.0 <= 3.0 < 6.0)
    # Bottom-right: -7.0m (should be red: 7.0 >= 6.0)
    # Center: +1.0m (should be green: 1.0 <= 1.0 < 3.0)

    # Load and check movement rank
    rank_dem = xdem.DEM(result.map_layers_dir / "movement_rank.tif")
    rank_data = rank_dem.data

    # Check that we have expected classifications
    assert np.any(rank_data == 1)  # Green
    assert np.any(rank_data == 2)  # Amber
    assert np.any(rank_data == 3)  # Red

    # Verify no nodata in outputs (scenario has no nodata)
    assert not np.any(result.output_mask)


def test_scenario2_nodata_edges(temp_output_dir, test_dtm_dir, db, test_job_id):
    """Test Scenario 2: Nodata at edges and boundaries."""
    a_path = test_dtm_dir / "scenario2_dem_a.tif"
    b_path = test_dtm_dir / "scenario2_dem_b.tif"

    config = ProcessingConfig(
        generate_report=False,
        generate_polygons=False,
    )

    db.create_job(test_job_id)
    result = run_pipeline(db, test_job_id, a_path, b_path, temp_output_dir, config)

    # Verify outputs exist
    assert (result.map_layers_dir / "elevation_change.tif").exists()

    # Verify nodata is properly handled
    # Edges should be masked
    assert np.any(result.output_mask)  # Should have some nodata

    # Check that nodata areas are NaN in elevation_change
    assert np.any(np.isnan(result.elevation_change[result.output_mask]))

    # Check that valid areas have finite values
    valid_mask = ~result.output_mask
    assert np.all(np.isfinite(result.elevation_change[valid_mask]))


def test_scenario3_mixed_nodata_values(temp_output_dir, test_dtm_dir, db, test_job_id):
    """Test Scenario 3: Different nodata values in DEM A and B."""
    a_path = test_dtm_dir / "scenario3_dem_a.tif"
    b_path = test_dtm_dir / "scenario3_dem_b.tif"

    config = ProcessingConfig(
        generate_report=False,
        generate_polygons=False,
    )

    db.create_job(test_job_id)
    result = run_pipeline(db, test_job_id, a_path, b_path, temp_output_dir, config)

    # Verify pipeline handles different nodata values
    assert (result.map_layers_dir / "elevation_change.tif").exists()

    # Nodata should be properly masked regardless of original values
    assert np.any(result.output_mask)


def test_scenario4_slope_variations(temp_output_dir, test_dtm_dir, db, test_job_id):
    """Test Scenario 4: Various slope conditions."""
    a_path = test_dtm_dir / "scenario4_dem_a.tif"
    b_path = test_dtm_dir / "scenario4_dem_b.tif"

    config = ProcessingConfig(
        generate_report=False,
        generate_polygons=False,
    )

    db.create_job(test_job_id)
    result = run_pipeline(db, test_job_id, a_path, b_path, temp_output_dir, config)

    # Verify slope calculation
    assert (result.map_layers_dir / "slope_degrees.tif").exists()

    # Load slope
    slope_dem = xdem.DEM(result.map_layers_dir / "slope_degrees.tif")
    slope_data = slope_dem.data

    # Check that slopes are reasonable (0-90 degrees)
    valid_slope = slope_data[~result.output_mask]
    assert np.all(valid_slope >= 0)
    assert np.all(valid_slope <= 90)

    # Should have some variation (not all flat)
    assert np.std(valid_slope) > 0.1


def test_scenario5_threshold_boundaries(temp_output_dir, test_dtm_dir, db, test_job_id):
    """Test Scenario 5: Movement values exactly at thresholds."""
    a_path = test_dtm_dir / "scenario5_dem_a.tif"
    b_path = test_dtm_dir / "scenario5_dem_b.tif"

    config = ProcessingConfig(
        t_green=1.0,
        t_amber=3.0,
        t_red=6.0,
        generate_report=False,
        generate_polygons=False,
    )

    db.create_job(test_job_id)
    result = run_pipeline(db, test_job_id, a_path, b_path, temp_output_dir, config)

    # Load movement rank
    rank_dem = xdem.DEM(result.map_layers_dir / "movement_rank.tif")
    rank_data = rank_dem.data

    # Verify threshold boundaries are handled correctly
    # Values at exactly 1.0m should be green (rank 1)
    # Values at exactly 3.0m should be amber (rank 2)
    # Values at exactly 6.0m should be red (rank 3)

    # Handle masked arrays from xdem
    if np.ma.isMaskedArray(rank_data):
        rank_data = rank_data.data

    # Check that we have expected classifications
    # Scenario 5 has values at/below/above thresholds, but may not have rank 0
    # if all values are >= 1.0m
    assert np.any(rank_data == 1)  # Green (1.0m threshold)
    assert np.any(rank_data == 2)  # Amber (3.0m threshold)
    assert np.any(rank_data == 3)  # Red (6.0m threshold)


def test_scenario6_sparse_nodata(temp_output_dir, test_dtm_dir, db, test_job_id):
    """Test Scenario 6: Sparse nodata (should pass validation)."""
    a_path = test_dtm_dir / "scenario6_dem_a.tif"
    b_path = test_dtm_dir / "scenario6_dem_b.tif"

    config = ProcessingConfig(
        generate_report=False,
        generate_polygons=False,
    )

    # Should pass validation (has >1% valid data)
    db.create_job(test_job_id)
    result = run_pipeline(db, test_job_id, a_path, b_path, temp_output_dir, config)

    # Verify processing completed
    assert (result.map_layers_dir / "elevation_change.tif").exists()

    # Should have some nodata but mostly valid
    valid_fraction = np.sum(~result.output_mask) / result.output_mask.size
    assert valid_fraction > 0.5  # More than 50% valid


def test_scenario7_mostly_nodata_validation_fails(test_dtm_dir, db, test_job_id):
    """Test Scenario 7: Mostly nodata (should fail validation)."""
    a_path = test_dtm_dir / "scenario7_dem_a.tif"
    b_path = test_dtm_dir / "scenario7_dem_b.tif"

    config = ProcessingConfig(
        generate_report=False,
        generate_polygons=False,
    )

    # Should raise ValueError due to insufficient valid data
    db.create_job(test_job_id)
    with pytest.raises(ValueError, match="insufficient valid data"):
        with tempfile.TemporaryDirectory() as tmpdir:
            run_pipeline(db, test_job_id, a_path, b_path, Path(tmpdir), config)


def test_scenario8_no_nodata_attribute(temp_output_dir, test_dtm_dir, db, test_job_id):
    """Test Scenario 8: DEMs without nodata attribute but with NaN/inf."""
    a_path = test_dtm_dir / "scenario8_dem_a.tif"
    b_path = test_dtm_dir / "scenario8_dem_b.tif"

    config = ProcessingConfig(
        generate_report=False,
        generate_polygons=False,
    )

    # Should handle NaN/inf values
    db.create_job(test_job_id)
    result = run_pipeline(db, test_job_id, a_path, b_path, temp_output_dir, config)

    # Verify outputs exist
    assert (result.map_layers_dir / "elevation_change.tif").exists()

    # NaN/inf should be handled (either masked or converted to NaN)
    # Check that elevation_change has finite values where mask is False
    valid_mask = ~result.output_mask
    if np.any(valid_mask):
        assert np.all(np.isfinite(result.elevation_change[valid_mask]))


def test_all_scenarios_generate_outputs(temp_output_dir, test_dtm_dir, db, test_job_id):
    """Test that all scenarios generate expected output files."""
    scenarios = [1, 2, 3, 4, 5, 6, 8]  # Skip 7 (fails validation)

    for scenario_num in scenarios:
        a_path = test_dtm_dir / f"scenario{scenario_num}_dem_a.tif"
        b_path = test_dtm_dir / f"scenario{scenario_num}_dem_b.tif"

        if not a_path.exists() or not b_path.exists():
            pytest.skip(f"Scenario {scenario_num} DTMs not found")

        scenario_out = temp_output_dir / f"scenario{scenario_num}"
        config = ProcessingConfig(
            generate_report=False,
            generate_polygons=False,
        )

        # Create a new job for each scenario
        job_id = f"{test_job_id}_{scenario_num}"
        db.create_job(job_id)
        result = run_pipeline(db, job_id, a_path, b_path, scenario_out, config)

        # Verify all expected outputs exist
        expected_files = [
            "diff.tif",
            "elevation_change.tif",
            "change_magnitude.tif",
            "change_direction.tif",
            "slope_degrees.tif",
            "movement_rank.tif",
        ]

        for filename in expected_files:
            filepath = result.map_layers_dir / filename
            assert filepath.exists(), f"Missing {filename} for scenario {scenario_num}"

            # Verify file is not empty
            assert filepath.stat().st_size > 0, (
                f"Empty file {filename} for scenario {scenario_num}"
            )


def test_nodata_propagation_consistency(temp_output_dir, test_dtm_dir, db, test_job_id):
    """Test that nodata is consistently handled across all output rasters."""
    a_path = test_dtm_dir / "scenario2_dem_a.tif"  # Has nodata
    b_path = test_dtm_dir / "scenario2_dem_b.tif"

    config = ProcessingConfig(
        generate_report=False,
        generate_polygons=False,
    )

    db.create_job(test_job_id)
    result = run_pipeline(db, test_job_id, a_path, b_path, temp_output_dir, config)

    # Load all output rasters
    elevation_change = xdem.DEM(result.map_layers_dir / "elevation_change.tif")
    change_magnitude = xdem.DEM(result.map_layers_dir / "change_magnitude.tif")
    change_direction = xdem.DEM(result.map_layers_dir / "change_direction.tif")
    slope = xdem.DEM(result.map_layers_dir / "slope_degrees.tif")
    movement_rank = xdem.DEM(result.map_layers_dir / "movement_rank.tif")

    # All should have the same nodata mask
    # Handle masked arrays from xdem
    def get_nodata_mask(dem: xdem.DEM) -> np.ndarray:
        """Extract nodata mask from DEM, handling masked arrays."""
        data = dem.data
        if np.ma.isMaskedArray(data):
            # For masked arrays, combine mask with nodata comparison
            mask = np.ma.getmaskarray(data)
            if dem.nodata is not None:
                nodata_vals = data.data == dem.nodata
                return mask | nodata_vals
            return mask
        else:
            # For regular arrays, just check nodata value
            if dem.nodata is not None:
                return data == dem.nodata
            return np.zeros_like(data, dtype=bool)

    nodata_mask_elev = get_nodata_mask(elevation_change)
    nodata_mask_mag = get_nodata_mask(change_magnitude)
    nodata_mask_dir = get_nodata_mask(change_direction)
    nodata_mask_slope = get_nodata_mask(slope)
    nodata_mask_rank = get_nodata_mask(movement_rank)

    # Check that nodata locations are consistent (allowing for different nodata values)
    # The output_mask should match where nodata appears in any output
    # Note: slope may have additional nodata at boundaries due to gradient calculation
    assert np.array_equal(result.output_mask, nodata_mask_elev)
    assert np.array_equal(result.output_mask, nodata_mask_mag)
    assert np.array_equal(result.output_mask, nodata_mask_dir)
    assert np.array_equal(result.output_mask, nodata_mask_rank)

    # Slope can have additional nodata at boundaries, but should include all original nodata
    # All original nodata locations should also be nodata in slope
    assert np.all(
        nodata_mask_slope[result.output_mask]
    )  # Slope nodata includes original nodata


def test_movement_rank_classification_ranges(
    temp_output_dir, test_dtm_dir, db, test_job_id
):
    """Test that movement ranking uses correct threshold ranges."""
    a_path = test_dtm_dir / "scenario5_dem_a.tif"  # Has threshold boundary values
    b_path = test_dtm_dir / "scenario5_dem_b.tif"

    config = ProcessingConfig(
        t_green=1.0,
        t_amber=3.0,
        t_red=6.0,
        generate_report=False,
        generate_polygons=False,
    )

    db.create_job(test_job_id)
    result = run_pipeline(db, test_job_id, a_path, b_path, temp_output_dir, config)

    # Load magnitude and rank
    magnitude_dem = xdem.DEM(result.map_layers_dir / "change_magnitude.tif")
    rank_dem = xdem.DEM(result.map_layers_dir / "movement_rank.tif")

    magnitude = magnitude_dem.data
    rank = rank_dem.data

    # Verify classification ranges
    valid_mask = ~result.output_mask

    # Rank 0: magnitude < t_green (1.0)
    rank_0_mask = (rank == 0) & valid_mask
    if np.any(rank_0_mask):
        assert np.all(magnitude[rank_0_mask] < 1.0)

    # Rank 1 (green): t_green <= magnitude < t_amber
    rank_1_mask = (rank == 1) & valid_mask
    if np.any(rank_1_mask):
        assert np.all(magnitude[rank_1_mask] >= 1.0)
        assert np.all(magnitude[rank_1_mask] < 3.0)

    # Rank 2 (amber): t_amber <= magnitude < t_red
    rank_2_mask = (rank == 2) & valid_mask
    if np.any(rank_2_mask):
        assert np.all(magnitude[rank_2_mask] >= 3.0)
        assert np.all(magnitude[rank_2_mask] < 6.0)

    # Rank 3 (red): magnitude >= t_red
    rank_3_mask = (rank == 3) & valid_mask
    if np.any(rank_3_mask):
        assert np.all(magnitude[rank_3_mask] >= 6.0)


def test_uncertainty_constant_outputs_exist(
    temp_output_dir, test_dtm_dir, db, test_job_id
):
    a_path = test_dtm_dir / "scenario1_dem_a.tif"
    b_path = test_dtm_dir / "scenario1_dem_b.tif"

    config = ProcessingConfig(
        uncertainty_mode="constant",
        sigma_a=0.10,
        sigma_b=0.10,
        sigma_coreg=0.20,
        k_sigma=1.96,
        generate_report=False,
        generate_polygons=False,
    )

    db.create_job(test_job_id)
    result = run_pipeline(db, test_job_id, a_path, b_path, temp_output_dir, config)

    assert (result.map_layers_dir / "sigma_dh.tif").exists()
    assert (result.map_layers_dir / "z_score.tif").exists()
    assert (result.map_layers_dir / "within_noise_mask.tif").exists()
